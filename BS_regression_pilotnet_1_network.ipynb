{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BS_regression_pilotnet_1_network.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNGzIgRadj4v/YOnEWL6M7p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiopaniego/BehaviorStudio-experiments/blob/main/BS_regression_pilotnet_1_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7fxmXdQbfWF"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoboticsLabURJC/2019-phd-sergio-paniego/blob/main/behavior_studio_networks/BS_recurrent_pilotnet_1_network.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCg3YqttguF5"
      },
      "source": [
        "The regression network retrieves a tuple **V** and **W** for each image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHvJgVYzlXmN"
      },
      "source": [
        "# When using Colab, check the GPU that is assigned and reload the runtime if its memory is low\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Er3t-_XXXL"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2kOzpVqX6PE"
      },
      "source": [
        "!ls \"/content/drive/My Drive\"\n",
        "!ls \"/content/drive/My Drive/complete_dataset.zip\"\n",
        "!unzip \"/content/drive/My Drive/curves_only.zip\"\n",
        "!unzip \"/content/drive/My Drive/complete_dataset.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEhJLk5qX62D"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Conv2D, BatchNormalization, Dropout, ConvLSTM2D, Reshape, Activation, MaxPooling2D\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def pilotnet_model(img_shape):\n",
        "    '''\n",
        "    Model of End to End Learning for Self-Driving Cars (NVIDIA)\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    model.add(BatchNormalization(epsilon=0.001, axis=-1, input_shape=img_shape))\n",
        "    model.add(Conv2D(24, (5, 5), strides=(2, 2), activation=\"relu\",padding='same'))\n",
        "    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation=\"relu\",padding='same'))\n",
        "    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation=\"relu\",padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\",padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\",padding='same'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1164, activation=\"relu\"))\n",
        "    model.add(Dense(100, activation=\"relu\"))\n",
        "    model.add(Dense(50, activation=\"relu\"))\n",
        "    model.add(Dense(10, activation=\"relu\"))\n",
        "    model.add(Dense(2))\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=\"mse\", metrics=['accuracy', 'mse', 'mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def tinypilotnet_model(img_shape):\n",
        "    model = Sequential()\n",
        "    model.add(BatchNormalization(epsilon=0.001, axis=-1, input_shape=img_shape))\n",
        "    model.add(Conv2D(8, (3, 3), strides=(2, 2), activation=\"relu\"))\n",
        "    model.add(Conv2D(8, (3, 3), strides=(2, 2), activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(50, activation=\"relu\"))\n",
        "    model.add(Dense(10, activation=\"relu\"))\n",
        "    model.add(Dense(2))\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=\"mse\", metrics=['accuracy', 'mse', 'mae'])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gENtloUbYBCS"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def load_data(folder):\n",
        "    name_folder = '/content/' + folder + '/Images/'\n",
        "    list_images = glob.glob(name_folder + '*')\n",
        "    print(list_images)\n",
        "    images = sorted(list_images, key=lambda x: int(x.split('/')[4].split('.png')[0]))\n",
        "    name_file = '/content/' + folder + '/data.json'\n",
        "    file = open(name_file, 'r')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return images, data\n",
        "\n",
        "def get_images(list_images, type_image, array_imgs):\n",
        "    # Read the images\n",
        "    for name in list_images:\n",
        "        img = cv2.imread(name)\n",
        "        if type_image == 'cropped':\n",
        "            img = img[240:480, 0:640]\n",
        "        img = cv2.resize(img, (int(img.shape[1] / 4), int(img.shape[0] / 4)))\n",
        "        array_imgs.append(img)\n",
        "\n",
        "    return array_imgs\n",
        "\n",
        "def parse_json(data, array):\n",
        "    # Process json\n",
        "    data_parse = data.split('}')[:-1]\n",
        "    for d in data_parse:\n",
        "        v = d.split('\"v\": ')[1]\n",
        "        d_parse = d.split(', \"v\":')[0]\n",
        "        w = d_parse.split(('\"w\": '))[1]\n",
        "        array.append((float(v), float(w)))\n",
        "\n",
        "    return array\n",
        "\n",
        "def preprocess_data(array, imgs):\n",
        "    # Data augmentation\n",
        "    # Take the image and just flip it and negate the measurement\n",
        "    flip_imgs = []\n",
        "    array_flip = []\n",
        "    for i in range(len(array)):\n",
        "        flip_imgs.append(cv2.flip(imgs[i], 1))\n",
        "        array_flip.append((array[i][0], -array[i][1]))\n",
        "    new_array = array + array_flip\n",
        "    new_array_imgs = imgs + flip_imgs\n",
        "    return new_array, new_array_imgs\n",
        "\n",
        "def add_extreme_data(array, imgs):\n",
        "    for i in range(0, len(array)):\n",
        "        if abs(array[i][1]) >= 1:\n",
        "            if abs(array[i][1]) >= 2:\n",
        "                num_iter = 10\n",
        "            else:\n",
        "                num_iter = 5\n",
        "            for j in range(0, num_iter):\n",
        "                array.append(array[i])\n",
        "                imgs.append(imgs[i])\n",
        "        if float(array[i][0]) <= 2:\n",
        "            for j in range(0, 1):\n",
        "                array.append(array[i])\n",
        "                imgs.append(imgs[i])\n",
        "    return array, imgs\n",
        "\n",
        "\n",
        "# Load data\n",
        "images, data = load_data('complete_dataset')\n",
        "images_curve, data_curve = load_data('curves_only')\n",
        "\n",
        "# CHANGE type_image\n",
        "type_image = 'cropped'\n",
        "#type_image='normal'\n",
        "\n",
        "# Preprocess images\n",
        "array_imgs = []\n",
        "array_imgs = get_images(images, type_image, array_imgs)\n",
        "array_imgs = get_images(images_curve, type_image, array_imgs)\n",
        "# Preprocess json\n",
        "array_annotations = []\n",
        "array_annotations = parse_json(data, array_annotations)\n",
        "array_annotations = parse_json(data_curve, array_annotations)\n",
        "\n",
        "\n",
        "if type_image == 'cropped':\n",
        "    img_shape = (65, 160, 3)\n",
        "else:\n",
        "    img_shape = (120, 160, 3)\n",
        "\n",
        "\n",
        "# Adapt the data\n",
        "array_annotations, array_imgs = preprocess_data(array_annotations, array_imgs)\n",
        "# x = x[:]\n",
        "array_annotations, array_imgs = add_extreme_data(array_annotations, array_imgs)\n",
        "images_train, images_validation, annotations_train, annotations_validation = train_test_split(array_imgs, array_annotations, test_size=0.20, random_state=42)\n",
        "\n",
        "\n",
        "# Adapt the data\n",
        "images_train = np.stack(images_train, axis=0)\n",
        "annotations_train = np.stack(annotations_train, axis=0)\n",
        "images_validation = np.stack(images_validation, axis=0)\n",
        "annotations_validation = np.stack(annotations_validation, axis=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrymDvsKYDUG"
      },
      "source": [
        "print(images_train[0].shape)\n",
        "print(annotations_train[0])\n",
        "print(img_shape)\n",
        "img_shape = (60, 160, 3)\n",
        "print(img_shape)\n",
        "\n",
        "model = pilotnet_model(img_shape)\n",
        "model = tinypilotnet_model(img_shape)\n",
        "batch_size = 64  # 16\n",
        "nb_epoch = 300  # 223\n",
        "\n",
        "\n",
        "if type_image == 'cropped':\n",
        "    # model_file = '/content/drive/My Drive/merged_model_pilotnet_cropped_100_dense_2.h5'\n",
        "    model_file = '/content/drive/My Drive/merged_model_tinypilotnet_cropped_300.h5'\n",
        "else:\n",
        "    model_file = '/content/drive/My Drive/model_pilotnet.h5'\n",
        "\n",
        "# Print layers\n",
        "print(model.summary())\n",
        "\n",
        "# Train\n",
        "model_history = model.fit(images_train, annotations_train, epochs=nb_epoch, batch_size=batch_size, verbose=2, validation_data=(images_train, annotations_train), callbacks=[])\n",
        "\n",
        "# Save the model\n",
        "model.save(model_file)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(images_validation, annotations_validation, verbose=0)\n",
        "print('Evaluating')\n",
        "print('Test loss: ', score[0])\n",
        "print('Test accuracy: ', score[1])\n",
        "print('Test mean squared error: ', score[2])\n",
        "print('Test mean absolute error: ', score[3])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlLl2wNx0gMA"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Loss Curves\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.plot(model_history.history['loss'], 'r', linewidth=3.0)\n",
        "plt.plot(model_history.history['val_loss'], 'b', linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n",
        "plt.xlabel('Epochs ', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.plot(model_history.history['accuracy'], 'r', linewidth=3.0)\n",
        "plt.plot(model_history.history['val_accuracy'], 'b', linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
        "plt.xlabel('Epochs ', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}