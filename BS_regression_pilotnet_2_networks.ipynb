{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BS_regression_pilotnet_2_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhpXVnSk4oKiJrmGKz03SD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiopaniego/BehaviorStudio-experiments/blob/main/BS_regression_pilotnet_2_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGei9kb6bZwZ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoboticsLabURJC/2019-phd-sergio-paniego/blob/main/behavior_studio_networks/BS_recurrent_pilotnet_2_networks.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSXdSYABpKVz"
      },
      "source": [
        "# When using Colab, check the GPU that is assigned and reload the runtime if its memory is low\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAsPdASw2ZqY"
      },
      "source": [
        "# Mount Google Drive to access images dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yn9ltRs2cjx"
      },
      "source": [
        "!ls \"/content/drive/My Drive\"\n",
        "!ls \"/content/drive/My Drive/complete_dataset.zip\"\n",
        "!unzip \"/content/drive/My Drive/curves_only.zip\"\n",
        "!unzip \"/content/drive/My Drive/complete_dataset.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ2Mv4Xq8SAA"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Conv2D, BatchNormalization, Dropout, ConvLSTM2D, Reshape, Activation, MaxPooling2D\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def pilotnet_model(img_shape):\n",
        "    '''\n",
        "    Model of End to End Learning for Self-Driving Cars (NVIDIA)\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    model.add(BatchNormalization(epsilon=0.001, axis=-1, input_shape=img_shape))\n",
        "    model.add(Conv2D(24, (5, 5), strides=(2, 2), activation=\"relu\",padding='same'))\n",
        "    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation=\"relu\",padding='same'))\n",
        "    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation=\"relu\",padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\",padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\",padding='same'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1164, activation=\"relu\"))\n",
        "    model.add(Dense(100, activation=\"relu\"))\n",
        "    model.add(Dense(50, activation=\"relu\"))\n",
        "    model.add(Dense(10, activation=\"relu\"))\n",
        "    model.add(Dense(1))\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=\"mse\", metrics=['accuracy', 'mse', 'mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def tinypilotnet_model(img_shape):\n",
        "    model = Sequential()\n",
        "    model.add(BatchNormalization(epsilon=0.001, axis=-1, input_shape=img_shape))\n",
        "    model.add(Conv2D(8, (3, 3), strides=(2, 2), activation=\"relu\"))\n",
        "    model.add(Conv2D(8, (3, 3), strides=(2, 2), activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(50, activation=\"relu\"))\n",
        "    model.add(Dense(10, activation=\"relu\"))\n",
        "    model.add(Dense(1))\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=\"mse\", metrics=['accuracy', 'mse', 'mae'])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs30irMcRbc3"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_data(folder):\n",
        "    name_folder = '/content/' + folder + '/Images/'\n",
        "    list_images = glob.glob(name_folder + '*')\n",
        "    print(list_images)\n",
        "    images = sorted(list_images, key=lambda x: int(x.split('/')[4].split('.png')[0]))\n",
        "    name_file = '/content/' + folder + '/data.json'\n",
        "    file = open(name_file, 'r')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return images, data\n",
        "\n",
        "def get_images(list_images, type_image, array_imgs):\n",
        "    # Read the images\n",
        "    for name in list_images:\n",
        "        img = cv2.imread(name)\n",
        "        if type_image == 'cropped':\n",
        "            img = img[240:480, 0:640]\n",
        "        img = cv2.resize(img, (int(img.shape[1] / 4), int(img.shape[0] / 4)))\n",
        "        array_imgs.append(img)\n",
        "\n",
        "    return array_imgs\n",
        "\n",
        "def parse_json(data, array_v, array_w):\n",
        "    # Process json\n",
        "    data_parse = data.split('}')[:-1]\n",
        "    for d in data_parse:\n",
        "        v = d.split('\"v\": ')[1]\n",
        "        d_parse = d.split(', \"v\":')[0]\n",
        "        w = d_parse.split(('\"w\": '))[1]\n",
        "        array_v.append(float(v))\n",
        "        array_w.append(float(w))\n",
        "\n",
        "    return array_v, array_w\n",
        "\n",
        "def preprocess_data(array_w, array_v, imgs):\n",
        "    # Take the image and just flip it and negate the measurement\n",
        "    flip_imgs = []\n",
        "    array_flip_w = []\n",
        "    for i in range(len(array_w)):\n",
        "        flip_imgs.append(cv2.flip(imgs[i], 1))\n",
        "        array_flip_w.append(-array_w[i])\n",
        "    new_array_w = array_w + array_flip_w\n",
        "    new_array_v = array_v + array_v\n",
        "    new_array_imgs = imgs + flip_imgs\n",
        "    return new_array_w, new_array_v, new_array_imgs\n",
        "\n",
        "def add_extreme_data(array_w, imgs_w, array_v, imgs_v):\n",
        "    for i in range(0, len(array_w)):\n",
        "        if abs(array_w[i]) >= 1:\n",
        "            if abs(array_w[i]) >= 2:\n",
        "                num_iter = 10\n",
        "            else:\n",
        "                num_iter = 5\n",
        "            for j in range(0, num_iter):\n",
        "                array_w.append(array_w[i])\n",
        "                imgs_w.append(imgs_w[i])\n",
        "        if float(array_v[i]) <= 2:\n",
        "            for j in range(0, 1):\n",
        "                array_v.append(array_v[i])\n",
        "                imgs_v.append(imgs_v[i])\n",
        "    return array_w, imgs_w, array_v, imgs_v\n",
        "\n",
        "\n",
        "# Load data\n",
        "images, data = load_data('complete_dataset')\n",
        "images_curve, data_curve = load_data('curves_only')\n",
        "\n",
        "# CHANGE type_image\n",
        "type_image = 'cropped'\n",
        "#type_image='normal'\n",
        "\n",
        "# Preprocess images\n",
        "array_imgs = []\n",
        "x = get_images(images, type_image, array_imgs)\n",
        "x = get_images(images_curve, type_image, x)\n",
        "# Preprocess json\n",
        "array_v = []\n",
        "array_w = []\n",
        "y_v, y_w = parse_json(data, array_v, array_w)\n",
        "y_v, y_w = parse_json(data_curve, y_v, y_w)\n",
        "\n",
        "\n",
        "\n",
        "if type_image == 'cropped':\n",
        "    img_shape = (65, 160, 3)\n",
        "else:\n",
        "    img_shape = (120, 160, 3)\n",
        "\n",
        "# Adapt the data\n",
        "y_w, y_v, x = preprocess_data(y_w, y_v, x)\n",
        "x_w = x[:]\n",
        "x_v = x[:]\n",
        "y_w, x_w, y_v, x_v = add_extreme_data(y_w, x_w, y_v, x_v)\n",
        "X_train_v, X_validation_v, y_train_v, y_validation_v = train_test_split(x_v, y_v, test_size=0.20, random_state=42)\n",
        "X_train_w, X_validation_w, y_train_w, y_validation_w = train_test_split(x_w, y_w, test_size=0.20, random_state=42)\n",
        "\n",
        "\n",
        "# Adapt the data\n",
        "X_train_v = np.stack(X_train_v, axis=0)\n",
        "y_train_v = np.stack(y_train_v, axis=0)\n",
        "X_validation_v = np.stack(X_validation_v, axis=0)\n",
        "y_validation_v = np.stack(y_validation_v, axis=0)\n",
        "\n",
        "X_train_w = np.stack(X_train_w, axis=0)\n",
        "y_train_w = np.stack(y_train_w, axis=0)\n",
        "X_validation_w = np.stack(X_validation_w, axis=0)\n",
        "y_validation_w = np.stack(y_validation_w, axis=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIf4jK7HXbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "df351b93-8391-4420-ecb7-90391d4ced82"
      },
      "source": [
        "#print(X_train_v[1].shape)\n",
        "#print(img_shape)\n",
        "img_shape = (60, 160, 3)\n",
        "#print(img_shape)\n",
        "\n",
        "model_v = pilotnet_model(img_shape)\n",
        "model_w = pilotnet_model(img_shape)\n",
        "#model_v = tinypilotnet_model(img_shape)\n",
        "#model_w = tinypilotnet_model(img_shape)\n",
        "batch_size_v = 64  # 16\n",
        "batch_size_w = 64\n",
        "nb_epoch_v = 300  # 223\n",
        "nb_epoch_w = 300  # 212\n",
        "\n",
        "#if type_image == 'cropped':\n",
        "#    model_file_v = '/content/drive/My Drive/model_pilotnet_cropped_300_v.h5'\n",
        "#    model_file_w = '/content/drive/My Drive/model_pilotnet_cropped_300_w.h5'\n",
        "#else:\n",
        "#    model_file_v = '/content/drive/My Drive/model_pilotnet_v.h5'\n",
        "#    model_file_w = '/content/drive/My Drive/model_pilotnet_w.h5'\n",
        "\n",
        "# Print layers\n",
        "print(model_v.summary())\n",
        "\n",
        "#  Train\n",
        "model_history_v = model_v.fit(X_train_v, y_train_v, epochs=nb_epoch_v, batch_size=batch_size_v, verbose=2, validation_data=(X_validation_v, y_validation_v), callbacks=[])\n",
        "# Save the model V\n",
        "model_v.save(model_file_v)\n",
        "\n",
        "#  Train\n",
        "model_history_w = model_w.fit(X_train_w, y_train_w, epochs=nb_epoch_w, batch_size=batch_size_w, verbose=2, validation_data=(X_validation_w, y_validation_w), callbacks=[])\n",
        "# Save the model W\n",
        "model_w.save(model_file_w)\n",
        "\n",
        "\n",
        "# We evaluate the model\n",
        "score = model_v.evaluate(X_validation_v, y_validation_v, verbose=0)\n",
        "print('Evaluating v')\n",
        "print('Test loss: ', score[0])\n",
        "print('Test accuracy: ', score[1])\n",
        "print('Test mean squared error: ', score[2])\n",
        "print('Test mean absolute error: ', score[3])\n",
        "\n",
        "score = model_w.evaluate(X_validation_w, y_validation_w, verbose=0)\n",
        "print('Evaluating w')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('Test mean squared error: ', score[2])\n",
        "print('Test mean absolute error: ', score[3])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_8 (Batch (None, 60, 160, 3)        12        \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 30, 80, 24)        1824      \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 15, 40, 36)        21636     \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 8, 20, 48)         43248     \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 8, 20, 64)         27712     \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 8, 20, 64)         36928     \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 10240)             0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1164)              11920524  \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 100)               116500    \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 12,173,955\n",
            "Trainable params: 12,173,949\n",
            "Non-trainable params: 6\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-67d2c2f4f4f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#  Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel_history_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m# Save the model V\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_v' is not defined"
          ]
        }
      ]
    }
  ]
}