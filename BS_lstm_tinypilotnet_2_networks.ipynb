{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BS_lstm_tinypilotnet_2_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnnYcQ7llao6zp+iOtahvK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiopaniego/BehaviorStudio-experiments/blob/main/BS_lstm_tinypilotnet_2_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcMG5aAibjCT"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoboticsLabURJC/2019-phd-sergio-paniego/blob/main/behavior_studio_networks/BS_lstm_tinypilotnet_2_networks.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwI0Jxn_pJjF"
      },
      "source": [
        "# When using Colab, check the GPU that is assigned and reload the runtime if its memory is low\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWGIJJ0s2WN2"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xOrUfte3HxY"
      },
      "source": [
        "# Unzip datasets\n",
        "!ls \"/content/drive/My Drive\"\n",
        "!ls \"/content/drive/My Drive/complete_dataset.zip\"\n",
        "!unzip \"/content/drive/My Drive/curves_only.zip\"\n",
        "!unzip \"/content/drive/My Drive/complete_dataset.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_5UPBKu3MMz"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten,Dense,Conv2D,BatchNormalization,Dropout,ConvLSTM2D,Reshape,Activation,MaxPooling2D, LSTM, Input\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# LSTM tinypilotnet\n",
        "def lstm_tinypilotnet_model(img_shape, type_image):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(8, (3, 3), strides=(2, 2), input_shape=img_shape, activation=\"relu\"))\n",
        "    model.add(Conv2D(16, (3, 3), strides=(2, 2), activation=\"relu\"))\n",
        "    model.add(Conv2D(32, (3, 3), strides=(2, 2), activation=\"relu\"))\n",
        "    if type_image == 'cropped':\n",
        "        model.add(Reshape((1, 6, 19, 32)))\n",
        "    else:\n",
        "        model.add(Reshape((1, 14, 19, 32)))\n",
        "\n",
        "    model.add(ConvLSTM2D(filters=32, kernel_size=(3, 3), padding=\"same\", return_sequences=True, input_shape=img_shape))\n",
        "    if type_image == 'cropped':\n",
        "        model.add(Reshape((6, 19, 32)))\n",
        "    else:\n",
        "        model.add(Reshape((14, 19, 40)))\n",
        "    model.add(Conv2D(1, (3, 3), strides=(2, 2), activation=\"relu\"))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=\"mse\", metrics=['accuracy', 'mse', 'mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ-aBZWY4o0o"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def load_data(folder):\n",
        "    name_folder = '/content/' + folder + '/Images/'\n",
        "    list_images = glob.glob(name_folder + '*')\n",
        "    print(list_images)\n",
        "    images = sorted(list_images, key=lambda x: int(x.split('/')[4].split('.png')[0]))\n",
        "    name_file = '/content/' + folder + '/data.json'\n",
        "    file = open(name_file, 'r')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return images, data\n",
        "\n",
        "def get_images(list_images, type_image, array_imgs):\n",
        "    # Read the images\n",
        "    for name in list_images:\n",
        "        img = cv2.imread(name)\n",
        "        if type_image == 'cropped':\n",
        "            img = img[240:480, 0:640]\n",
        "        img = cv2.resize(img, (int(img.shape[1] / 4), int(img.shape[0] / 4)))\n",
        "        array_imgs.append(img)\n",
        "\n",
        "    return array_imgs\n",
        "\n",
        "def parse_json(data, array_v, array_w):\n",
        "    # Process json\n",
        "    data_parse = data.split('}')[:-1]\n",
        "    for d in data_parse:\n",
        "        v = d.split('\"v\": ')[1]\n",
        "        d_parse = d.split(', \"v\":')[0]\n",
        "        w = d_parse.split(('\"w\": '))[1]\n",
        "        array_v.append(float(v))\n",
        "        array_w.append(float(w))\n",
        "\n",
        "    return array_v, array_w\n",
        "\n",
        "def preprocess_data(array_w, array_v, imgs):\n",
        "    # Take the image and just flip it and negate the measurement\n",
        "    flip_imgs = []\n",
        "    array_flip_w = []\n",
        "    for i in range(len(array_w)):\n",
        "        flip_imgs.append(cv2.flip(imgs[i], 1))\n",
        "        array_flip_w.append(-array_w[i])\n",
        "    new_array_w = array_w + array_flip_w\n",
        "    new_array_v = array_v + array_v\n",
        "    new_array_imgs = imgs + flip_imgs\n",
        "    return new_array_w, new_array_v, new_array_imgs\n",
        "\n",
        "def add_extreme_data(array_w, imgs_w, array_v, imgs_v):\n",
        "    for i in range(0, len(array_w)):\n",
        "        if abs(array_w[i]) >= 1:\n",
        "            if abs(array_w[i]) >= 2:\n",
        "                num_iter = 10\n",
        "            else:\n",
        "                num_iter = 5\n",
        "            for j in range(0, num_iter):\n",
        "                array_w.append(array_w[i])\n",
        "                imgs_w.append(imgs_w[i])\n",
        "        if float(array_v[i]) <= 2:\n",
        "            for j in range(0, 1):\n",
        "                array_v.append(array_v[i])\n",
        "                imgs_v.append(imgs_v[i])\n",
        "    return array_w, imgs_w, array_v, imgs_v\n",
        "\n",
        "\n",
        "# Load data\n",
        "images, data = load_data('complete_dataset')\n",
        "images_curve, data_curve = load_data('curves_only')\n",
        "\n",
        "# CHANGE type_image\n",
        "type_image = 'cropped'\n",
        "#type_image='normal'\n",
        "\n",
        "# Preprocess images\n",
        "array_imgs = []\n",
        "x = get_images(images, type_image, array_imgs)\n",
        "x = get_images(images_curve, type_image, x)\n",
        "# Preprocess json\n",
        "array_v = []\n",
        "array_w = []\n",
        "y_v, y_w = parse_json(data, array_v, array_w)\n",
        "y_v, y_w = parse_json(data_curve, y_v, y_w)\n",
        "\n",
        "\n",
        "if type_image == 'cropped':\n",
        "    img_shape = (65, 160, 3)\n",
        "else:\n",
        "    img_shape = (120, 160, 3)\n",
        "\n",
        "\n",
        "# Adapt the data\n",
        "y_w, y_v, x = preprocess_data(y_w, y_v, x)\n",
        "x_w = x[:]\n",
        "x_v = x[:]\n",
        "y_w, x_w, y_v, x_v = add_extreme_data(y_w, x_w, y_v, x_v)\n",
        "X_train_v, X_validation_v, y_train_v, y_validation_v = train_test_split(x_v, y_v, test_size=0.20, random_state=42)\n",
        "X_train_w, X_validation_w, y_train_w, y_validation_w = train_test_split(x_w, y_w, test_size=0.20, random_state=42)\n",
        "\n",
        "\n",
        "# Adapt the data\n",
        "X_train_v = np.stack(X_train_v, axis=0)\n",
        "y_train_v = np.stack(y_train_v, axis=0)\n",
        "X_validation_v = np.stack(X_validation_v, axis=0)\n",
        "y_validation_v = np.stack(y_validation_v, axis=0)\n",
        "\n",
        "X_train_w = np.stack(X_train_w, axis=0)\n",
        "y_train_w = np.stack(y_train_w, axis=0)\n",
        "X_validation_w = np.stack(X_validation_w, axis=0)\n",
        "y_validation_w = np.stack(y_validation_w, axis=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "720obNqU4r0z",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "img_shape = (60, 160, 3)\n",
        "model_v = lstm_tinypilotnet_model(img_shape, 'cropped')\n",
        "model_w = lstm_tinypilotnet_model(img_shape, 'cropped')\n",
        "batch_size_v = 12  # 16\n",
        "batch_size_w = 12\n",
        "nb_epoch_v = 150  # 223\n",
        "nb_epoch_w = 150  # 212\n",
        "\n",
        "\n",
        "if type_image == 'cropped':\n",
        "    model_file_v = '/content/drive/My Drive/model_lstm_tinypilotnet_cropped_150_v.h5'\n",
        "    model_file_w = '/content/drive/My Drive/model_lstm_tinypilotnet_cropped_150_w.h5'\n",
        "else:\n",
        "    model_file_v = '/content/drive/My Drive/model_lstm_tinypilotnet_v.h5'\n",
        "    model_file_w = '/content/drive/My Drive/model_lstm_tinypilotnet_w.h5'\n",
        "\n",
        "# Print layers\n",
        "print(model_v.summary())\n",
        "\n",
        "model_history_v = model_v.fit(X_train_v, y_train_v, epochs=nb_epoch_v, batch_size=batch_size_v, verbose=2, validation_data=(X_validation_v, y_validation_v), callbacks=[])\n",
        "\n",
        "# Save the model V\n",
        "model_v.save(model_file_v)\n",
        "\n",
        "model_history_w = model_w.fit(X_train_w, y_train_w, epochs=nb_epoch_w, batch_size=batch_size_w, verbose=2, validation_data=(X_validation_w, y_validation_w), callbacks=[])\n",
        "\n",
        "\n",
        "# Save the model W\n",
        "model_w.save(model_file_w)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "score = model_v.evaluate(X_validation_v, y_validation_v, verbose=0)\n",
        "print('Evaluating v')\n",
        "print('Test loss: ', score[0])\n",
        "print('Test accuracy: ', score[1])\n",
        "print('Test mean squared error: ', score[2])\n",
        "print('Test mean absolute error: ', score[3])\n",
        "\n",
        "score = model_w.evaluate(X_validation_w, y_validation_w, verbose=0)\n",
        "print('Evaluating w')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('Test mean squared error: ', score[2])\n",
        "print('Test mean absolute error: ', score[3])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}